{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62300715",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2318961672.py, line 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 84\u001b[0;36m\u001b[0m\n\u001b[0;31m    step\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Constants\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 9\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "data_dir = 'VGG_Spectograms/'\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)  # Splitting 80% for training, 20% for testing\n",
    "\n",
    "# Load and preprocess data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',  # Set as training data\n",
    "    seed=42,  # Random seed for reproducibility\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # Set as validation data\n",
    "    seed=42,  # Same random seed as training data\n",
    "    shuffle=True)\n",
    "\n",
    "# Sanity check to ensure that the class indices are consistent\n",
    "assert train_generator.class_indices == validation_generator.class_indices\n",
    "\n",
    "# Load pre-trained InceptionV3 model without top layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Add global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout layer\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add a final softmax layer\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    predictions\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the filepath to save the best model\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_inception_model.h5', \n",
    "                                   monitor='val_accuracy', \n",
    "                                   save_best_only=True, \n",
    "                                   mode='max', \n",
    "                                   verbose=1)\n",
    "\n",
    "# Train the model with the ModelCheckpoint callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[model_checkpoint])\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(validation_generator)\n",
    "print(\"Best Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
